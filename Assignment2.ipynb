{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 131,
      "metadata": {
        "id": "JnYyDTVgfwLX"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Description**: The dataset consists of feature vectors belong to 12330 sessions and the data were constituted so that each session would belong to a different user in a 1-year period to avoid any tendency to a specific campaign, special day, user profile, or period. Moreover, among the 12330 sessions in the dataset, 84.5% (10422) were negative class samples that did not end with shopping and the rest (1908) were positive class samples ending with shopping.\n",
        "\n",
        "Additional Variable Information: The dataset comprises 10 numerical and 8 categorical attributes, with the 'Revenue' attribute serving as the class label. Metrics such as \"Administrative,\" \"Administrative Duration,\" \"Informational,\" \"Informational Duration,\" \"Product Related,\" and \"Product Related Duration\" quantify the number of pages visited and the time spent on different page categories during a session. These values are derived from the URL information of the visited pages, dynamically updated in real-time as users navigate through the site. The features \"Bounce Rate,\" \"Exit Rate,\" and \"Page Value\" correspond to metrics measured by \"Google Analytics\" for each page in the e-commerce site. \"Bounce Rate\" indicates the percentage of visitors who enter a page and leave without triggering additional requests to the analytics server. \"Exit Rate\" calculates the percentage of pageviews that were the last in a session. Meanwhile, \"Page Value\" represents the average value of a page visited before completing an e-commerce transaction. The \"Special Day\" feature gauges the proximity of site visits to specific occasions (e.g., Mother’s Day, Valentine's Day), where transactions are more likely to occur. This attribute's value considers e-commerce dynamics, such as the duration between the order date and delivery date. For instance, around Valentine’s Day, the value is nonzero between February 2 and February 12, zero before and after unless close to another special day, reaching a maximum of 1 on February 8. Additionally, the dataset includes information on the operating system, browser, region, traffic type, visitor type (returning or new), a Boolean indicator for weekend visits, and the month of the year.\n",
        "\n"
      ],
      "metadata": {
        "id": "rf4VdApqqjPk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install requests\n",
        "!pip install tabulate\n",
        "!pip install \"colorama>=0.3.8\"\n",
        "!pip install future"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "88TXlKS6jJ9T",
        "outputId": "fd756d7b-1fa1-428d-eaf8-b5ad30048e8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2024.2.2)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (0.9.0)\n",
            "Requirement already satisfied: colorama>=0.3.8 in /usr/local/lib/python3.10/dist-packages (0.4.6)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (0.18.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -f http://h2o-release.s3.amazonaws.com/h2o/latest_stable_Py.html h2o\n"
      ],
      "metadata": {
        "id": "v9X2ZySgjzUU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import h2o\n",
        "from h2o.automl import H2OAutoML\n",
        "import random, os, sys\n",
        "from datetime import datetime\n",
        "import pandas as pd\n",
        "import logging\n",
        "import csv\n",
        "import optparse\n",
        "import time\n",
        "import json\n",
        "from distutils.util import strtobool\n",
        "import psutil\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "sns.set(context=\"notebook\", palette=\"Spectral\", style = 'darkgrid' ,font_scale = 1.5, color_codes=True)\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import statsmodels.api as sm\n",
        "from statsmodels.compat import lzip\n",
        "import statsmodels.stats.api as sms\n",
        "from sklearn.model_selection import train_test_split\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.linear_model import LassoCV\n",
        "from sklearn.linear_model import RidgeCV\n",
        "from sklearn.metrics import r2_score,mean_squared_error,mean_absolute_error\n",
        "from yellowbrick.regressor import ResidualsPlot\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import GridSearchCV,RandomizedSearchCV"
      ],
      "metadata": {
        "id": "W8An4WV8j63j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "min_mem_size=6\n",
        "run_time=222"
      ],
      "metadata": {
        "id": "DRgegE29kFLz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pct_memory=0.5\n",
        "virtual_memory=psutil.virtual_memory()\n",
        "min_mem_size=int(round(int(pct_memory*virtual_memory.available)/1073741824,0))\n",
        "print(min_mem_size)"
      ],
      "metadata": {
        "id": "Jy1qyS2DkGoO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "port_no=random.randint(5555,55555)\n",
        "\n",
        "#  h2o.init(strict_version_check=False,min_mem_size_GB=min_mem_size,port=port_no) # start h2o\n",
        "try:\n",
        "  h2o.init(strict_version_check=False,min_mem_size_GB=min_mem_size,port=port_no) # start h2o\n",
        "except:\n",
        "  logging.critical('h2o.init')\n",
        "  h2o.download_all_logs(dirname=logs_path, filename=logfile)\n",
        "  h2o.cluster().shutdown()\n",
        "  sys.exit(2)"
      ],
      "metadata": {
        "id": "f0xZXq76kThu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "x1Kz567blmd2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "url = \"https://github.com/shwetackhade/Data-Science-Engineering-Methods-and-Tools/blob/main/online_shoppers_intention.csv?raw=true\"\n",
        "df = h2o.import_file(path = url)\n",
        "dff = pd.read_csv('https://github.com/shwetackhade/Data-Science-Engineering-Methods-and-Tools/blob/main/online_shoppers_intention.csv?raw=true')"
      ],
      "metadata": {
        "id": "5bVEQOahki0x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dff.head()"
      ],
      "metadata": {
        "id": "3e_EKkX3oCYl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dff.describe()"
      ],
      "metadata": {
        "id": "Zy2r_YTnoJBU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dff.isnull()"
      ],
      "metadata": {
        "id": "5AK1Az6drBMe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.types"
      ],
      "metadata": {
        "id": "eVIn87-7t0mX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dff.dtypes"
      ],
      "metadata": {
        "id": "9zaouoNEsm3z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dff['Revenue'].value_counts()"
      ],
      "metadata": {
        "id": "Pjr6j_8KzJcz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dff.shape"
      ],
      "metadata": {
        "id": "qeBwDEZqs8IA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dff.Revenue = dff.Revenue.astype(int)\n",
        "dff.Weekend = dff.Weekend.astype(int)\n",
        "dff.VisitorType = dff.VisitorType.replace(\n",
        "    {'Returning_Visitor': '0',\n",
        "    'Other': '2',\n",
        "    'New_Visitor': '1',\n",
        "    }).astype(int)\n",
        "dff.Month = dff.Month.replace(\n",
        "    {'Jan': '1',\n",
        "    'Feb': '2',\n",
        "    'Mar': '3',\n",
        "    'Apr': '4',\n",
        "    'May': '5',\n",
        "    'June': '6',\n",
        "    'Jul': '7',\n",
        "    'Aug': '8',\n",
        "    'Sep': '9',\n",
        "    'Oct': '10',\n",
        "    'Nov': '11',\n",
        "    'Dec': '12',\n",
        "    }).astype(int)"
      ],
      "metadata": {
        "id": "06yMiHb0uoRy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dff.Month"
      ],
      "metadata": {
        "id": "Vq5tEA97uynu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pct_rows=0.80\n",
        "df_train, df_test = df.split_frame([pct_rows])"
      ],
      "metadata": {
        "id": "waBdOXl5wVwg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_train.shape)\n",
        "print(df_test.shape)"
      ],
      "metadata": {
        "id": "qEhe8Iz8weMV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X=df.columns\n",
        "print(X)"
      ],
      "metadata": {
        "id": "gWQGPJh5wkBL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_numeric ='Revenue'\n",
        "X.remove(y_numeric)\n",
        "print(X)\n"
      ],
      "metadata": {
        "id": "l7z791t4wpsi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**H20 AutoML Execution**"
      ],
      "metadata": {
        "id": "zOO34J7Ow8rz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "aml = H2OAutoML(max_runtime_secs=run_time, seed=1)\n"
      ],
      "metadata": {
        "id": "mzJ91JICw_yf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "aml.train(x=X,y=y_numeric,training_frame=df_train)\n"
      ],
      "metadata": {
        "id": "xfo6cjWixPiE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Interpreting the above results**\n",
        "\n"
      ],
      "metadata": {
        "id": "QWD2lsMZ24aW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(aml.leaderboard)"
      ],
      "metadata": {
        "id": "VLejmMVRyiDy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "gvQ4XalG22s5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Analysing the Analysing relation between all variables**"
      ],
      "metadata": {
        "id": "HEX3FGw-3DYr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "\n",
        "# Encode categorical variables\n",
        "#dff_encoded = pd.get_dummies(dff, columns=['Month', 'VisitorType'], drop_first=True)\n",
        "\n",
        "# Select relevant columns, ensuring all are numeric\n",
        "Multic = dff[['Administrative', 'Administrative_Duration', 'Informational', 'Informational_Duration', 'ProductRelated', 'ProductRelated_Duration', 'BounceRates', 'ExitRates', 'PageValues', 'SpecialDay', 'OperatingSystems', 'Browser', 'Region', 'TrafficType', 'Revenue']]\n",
        "\n",
        "# Compute VIF\n",
        "vif = pd.DataFrame()\n",
        "vif[\"variables\"] = Multic.columns\n",
        "vif[\"VIF\"] = [variance_inflation_factor(Multic.values, i) for i in range(Multic.shape[1])]\n",
        "vif\n"
      ],
      "metadata": {
        "id": "knSpGY4sqXow"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import statsmodels.formula.api as smf #OLS model Library\n",
        "results = smf.ols('Revenue ~ Administrative + Administrative_Duration + Informational + Informational_Duration + ProductRelated + ProductRelated_Duration + BounceRates + ExitRates + PageValues + SpecialDay + Month + OperatingSystems + Browser + Region + TrafficType + VisitorType + Weekend', data=dff).fit()\n",
        "results.summary()"
      ],
      "metadata": {
        "id": "vY2EdzKCwXvZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "AXIo1RAQyUMS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dff.corr()\n"
      ],
      "metadata": {
        "id": "HiMlNo_2y2Bq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Representing Matrix as a plot\n",
        "from IPython.core.pylabtools import figsize\n",
        "f,ax=plt.subplots(figsize=(10,6))\n",
        "\n",
        "sns.heatmap(dff.corr(),center=0, linewidths=0.8,cmap='coolwarm',annot=True, annot_kws={\"size\": 9})\n",
        "plt.title('Variable Correlation')"
      ],
      "metadata": {
        "id": "crFkZjjoz7mC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.pairplot(dff)\n"
      ],
      "metadata": {
        "id": "tyFMxB6M0Ts_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**H20 AutoML Rexecution on new model**\n",
        "Dropping the variables that are not significant for determining Price. Passing this new model again through H20AutoML. Here, we are repeating the entire process exactly as above whilst ignoring the unecessary features."
      ],
      "metadata": {
        "id": "rPn-6oTW9EBb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dropping Operating System, Browser,Weekend and Traffic Type\n"
      ],
      "metadata": {
        "id": "NgyCG1ww7-Je"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df1=df.drop(['OperatingSystems', 'Browser','Weekend','TrafficType'], axis=1)"
      ],
      "metadata": {
        "id": "_1ku1-TT1Adp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1_train, df1_test = df1.split_frame([pct_rows])\n"
      ],
      "metadata": {
        "id": "bExUI1-l9XyW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X1=df1.columns\n",
        "print(X1)"
      ],
      "metadata": {
        "id": "r5WPu58F9bkv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Seperate Dependent variable from Independent variable\n",
        "y1_numeric ='Revenue'\n",
        "X1.remove(y1_numeric)\n",
        "print(X1)"
      ],
      "metadata": {
        "id": "s-ykCFEX9jZi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "aml1 = H2OAutoML(max_runtime_secs=run_time, seed=1)\n"
      ],
      "metadata": {
        "id": "Ymg3xfAQ97qA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "aml1.train(x=X1,y=y1_numeric,training_frame=df1_train)\n"
      ],
      "metadata": {
        "id": "mqcBDd3c-AkU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(aml1.leaderboard)\n"
      ],
      "metadata": {
        "id": "NCYLuvg5_CA4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#assign index values to all the models generated\n",
        "model_index=0\n",
        "glm_index=0\n",
        "glm_model=''\n",
        "aml1_leaderboard_df1=aml1.leaderboard.as_data_frame()\n",
        "models_dict={}\n",
        "for m in aml1_leaderboard_df1['model_id']:\n",
        "  models_dict[m]=model_index\n",
        "  if 'StackedEnsemble' not in m:\n",
        "    break\n",
        "  model_index=model_index+1\n",
        "\n",
        "for m in aml1_leaderboard_df1['model_id']:\n",
        "  if 'GLM' in m:\n",
        "    models_dict[m]=glm_index\n",
        "    break\n",
        "  glm_index=glm_index+1\n",
        "models_dict"
      ],
      "metadata": {
        "id": "4fgUsfa1_JWv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#print the index value of best model\n",
        "print(model_index)\n",
        "best_model1 = h2o.get_model(aml1.leaderboard[model_index,'model_id'])"
      ],
      "metadata": {
        "id": "-bwA3PnA_RTt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_model1.algo\n"
      ],
      "metadata": {
        "id": "Qnuq3_9W_Vim"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#plot variables in order of their importance for Revenue prediction\n",
        "if best_model1.algo in ['gbm','drf','xrt','xgboost']:\n",
        "    best_model1.varimp_plot()"
      ],
      "metadata": {
        "id": "r70tkW88_ZWA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if glm_index is not 0:\n",
        "  print(glm_index)\n",
        "  glm_model1=h2o.get_model(aml1.leaderboard[glm_index,'model_id'])\n",
        "  print(glm_model1.algo)\n",
        "  glm_model1.std_coef_plot()"
      ],
      "metadata": {
        "id": "_NyCf4OB_dXs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Checking if assumptions violated**"
      ],
      "metadata": {
        "id": "JRgFPKV-_n_E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()\n"
      ],
      "metadata": {
        "id": "dxjpRArrC5HW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dff.describe()"
      ],
      "metadata": {
        "id": "tq0_gVOpRY2E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Seperating the predictor and target variables\n",
        "A=dff.drop(['Revenue'],axis=1)\n",
        "B=dff['Revenue']"
      ],
      "metadata": {
        "id": "hDIq2zv8_t5m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "A_train,A_test,b_train,b_test=tts(A,B,test_size=0.2,random_state=42)\n"
      ],
      "metadata": {
        "id": "BT7_CkY5WnLO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming A is your feature set and B is your target variable, both in an H2O Frame\n",
        "split_frames = train_test_split(A,test_size=0.2,random_state=42) # Splits A into two frames with 80% of the data in the first frame\n",
        "A_train = split_frames[0]\n",
        "A_test = split_frames[1]\n",
        "\n",
        "split_frames_b = train_test_split(B,test_size=0.2,random_state=42)  # Do the same for B if it's a separate frame\n",
        "b_train = split_frames_b[0]\n",
        "b_test = split_frames_b[1]\n",
        "\n"
      ],
      "metadata": {
        "id": "rbdCbYYwFRV_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model1 = sm.OLS(b_train,sm.add_constant(A_train[X])).fit()"
      ],
      "metadata": {
        "id": "00S8y8sacLwq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "b_pred = model1.predict(sm.add_constant(A_train[X]))\n"
      ],
      "metadata": {
        "id": "1EvkiH-Fe6PN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "residuals = b_train-b_pred\n",
        "mean_residuals = np.mean(residuals)\n",
        "print(\"Mean of Residuals {}\".format(mean_residuals))"
      ],
      "metadata": {
        "id": "VJrZ5y1Xggri"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "p = sns.distplot(residuals,kde=True)\n",
        "p = plt.title('Normality of error terms/residuals')\n"
      ],
      "metadata": {
        "id": "DIcHQoQmgkez"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pylab\n",
        "import scipy.stats as stats\n",
        "stats.probplot(residuals, dist=\"norm\", plot=pylab)\n",
        "pylab.show()"
      ],
      "metadata": {
        "id": "ej9flwn3gp8Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.histplot(dff.Revenue, kde = True)\n"
      ],
      "metadata": {
        "id": "-SngdBDmgwt-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ridge Regularization in H20\n",
        "\n"
      ],
      "metadata": {
        "id": "68Ch8TVbhKmx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from h2o.estimators.glm import H2OGeneralizedLinearEstimator\n",
        "house_glm = H2OGeneralizedLinearEstimator(family = 'gaussian', lambda_ = 0, compute_p_values = True)\n",
        "house_glm_regularization = H2OGeneralizedLinearEstimator(family = 'gaussian', lambda_ = .001, alpha = 0)\n"
      ],
      "metadata": {
        "id": "3X_IQlzGhMKD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1_train.types[\"Revenue\"]"
      ],
      "metadata": {
        "id": "g8byrD-ailpz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1_train[\"Revenue\"] = df1_train[\"Revenue\"].asnumeric()"
      ],
      "metadata": {
        "id": "Ch0EVfGbipj3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "house_glm_regularization.train(x = X1, y = y1_numeric, training_frame = df1_train)"
      ],
      "metadata": {
        "id": "C890u_zzittQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Model details without regularization\n",
        "house_glm.train(x = X1, y = y1_numeric, training_frame = df1_train)\n",
        "\n"
      ],
      "metadata": {
        "id": "5kkvxWWni3Yx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "DATA REPORT"
      ],
      "metadata": {
        "id": "f9bputXhi8A2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "exa = aml1.explain(df1_test)\n"
      ],
      "metadata": {
        "id": "0HyEHkcHi9Wy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hyperparameter Tuning\n"
      ],
      "metadata": {
        "id": "dm_wcEzkj-dD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "s = dff['Revenue']\n",
        "\n",
        "t = dff.drop(['Revenue'], axis = 1)"
      ],
      "metadata": {
        "id": "gTwWA63RkB--"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "from sklearn.model_selection import RandomizedSearchCV"
      ],
      "metadata": {
        "id": "H7hIcDcakNbX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t_train, t_test, s_train, s_test = train_test_split (t, s, random_state = 42, test_size = 0.2)\n"
      ],
      "metadata": {
        "id": "zyJJ9VTIkoKq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "mode = RandomForestRegressor()\n",
        "\n",
        "param_vals = {'max_depth': [200, 500, 800, 1100], 'n_estimators': [100,200, 300, 400], 'min_samples_split' : [2,3,5]\n",
        "\n",
        "}\n",
        "\n",
        "random_rf = RandomizedSearchCV(estimator=mode, param_distributions=param_vals,\n",
        "\n",
        "n_iter=10, scoring='accuracy', cv=5,\n",
        "\n",
        "refit=True, n_jobs=-1)\n",
        "\n",
        "#Training and prediction\n",
        "\n",
        "\n",
        "\n",
        "random_rf.fit(t_train, s_train)\n",
        "\n",
        "preds = random_rf.best_estimator_.predict(t_test)"
      ],
      "metadata": {
        "id": "6gxwB1atlIEq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random_rf.best_params_\n"
      ],
      "metadata": {
        "id": "0RuoBSDLmNZ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**CONCLUSION**:\n",
        "\n",
        "AutoML was utilized for revenue prediction, taking into account various factors such as Variance Inflation Factor (VIF), p-values, and additional tests to exclude certain independent variables. The H2O.ai framework facilitated the training and testing of dataset variables related to the online consumer purchase intent analysis, identifying 'gbm' as the optimal model. The findings indicate that the suggested linear regression approach is capable of assessing and forecasting housing prices to a certain degree. However, it's acknowledged that the model's predictive precision has limitations at specific junctures, necessitating further enhancements through ongoing research. Future studies on these models may benefit from implementing strategies such as outlier removal and the application of ensemble or boosting techniques to improve prediction accuracy.\n",
        "\n",
        "\n",
        "\n",
        "1) Is the relationship significant?\n",
        "Ans: A relationship is considered to be statistically significant if the p-value associated with the variables is below 0.05. The p-value represents the likelihood of observing a result as extreme as, or more so, than the one observed, under the assumption that the null hypothesis holds true. A low p-value indicates a substantial difference between the two compared groups, suggesting the null hypothesis can be rejected. In this model, the p-value was determined through two methods. Using the OLS (Ordinary Least Squares) approach, it was found that the p-values for variables such as 'Administrative', 'Administrative_Duration', 'Informational', 'Informational_Duration', 'Browser', 'TrafficType', and 'Weekend' exceeded 0.05. This observation leads to the conclusion that the p-values for the remaining variables in the dataset are below 0.05, thereby affirming the significance of the relationship for the dataset under consideration.\n",
        "\n",
        "2) Are any model assumptions violated?\n",
        "Ans:\n",
        "- Linear relationship- The graph for dependent and independent variable needs to be linear by keeping other variables constant. When target variable is plotted against all other independent variables, linear relation is observed for few of them. Hence this assumption is not violated.\n",
        "\n",
        "- Homoscedasticity which means normality of the error distribution - The plot for residuals should be normally distributed i.e., it should form a bell-curve shape. For this model the same is achieved.\n",
        "\n",
        "\n",
        "3)Is there any multicollinearity in the model?\n",
        "Ans: Multicollinearity occurs in a model when there is a high correlation between two or more independent variables. This condition is problematic because it diminishes the reliability of the statistical significance of individual independent variables. To identify multicollinearity, one can utilize a correlation matrix or compute the Variance Inflation Factor (VIF) for each variable. In a correlation matrix, a coefficient near +1 or -1 indicates a strong correlation between two variables. A VIF value exceeding 10 suggests the presence of multicollinearity. In the discussed model, although no variables exhibited a VIF greater than 10, certain variables had p-values higher than 0.05. Removing these variables and reassessing the model led to the desired results. Presently, there is a significant correlation observed between Bounce Rate and Exit Rate.\n",
        "\n",
        "4) In the multivariate models are predictor variables independent of all the other predictor variables?\n",
        "Ans: Variables are said to be independent when there is no relation between them. To check this relation, correlation matrix can be used, or it can be observed from graphs too whether there is any pattern followed or not. When correlation matrix is computed for the model, it can be observed that ExitRates and BounceRates are correlated to each other. Other than those other predictors are independent from each other.\n",
        "\n",
        "5) In multivariate models rank the most significant predictor variables and exclude insignificant ones from the model.\n",
        "Ans: From the variable importance plot, the most to least important variables are displayed. For my model PageValues, Month, Bouncerates, ProductRelated are top 4 most important variables to determine Revenue. VIF and p-values for OperatingSystems, Browser, Weekend, and TrafficType was higherrafficType was high than the ideal values. So those variables were excluded from the model.\n",
        "\n",
        "6) Does the model make sense?\n",
        "Ans: For a model to make sense it should follow all the assumptions and have p value, VIF between their respective ranges. RMSE should be as low as possible considering the minimum and maximum values of the target variable. So overall the model makes sense. To increase the accuracy, some additional variables can be dropped depending on their importance. Furthermore, outliers can be removed or boosting, or ensemble model can be used.\n",
        "\n",
        "7) Does regularization help?\n",
        "Ans: Regularization is a technique used for tuning the random noise function by adding an additional term to noise function. This additional term controls the excessively fluctuating function such that the coefficients don’t take extreme values and the prediction of target value for test data is not highly affected. The main use of Regularization is to minimize the validation loss and try to improve the accuracy of the model. For this model Ridge Regularization was used on training data. It was observed that Root Mean Square Error (RMSE) and R2 was calculated twice, once when regularization was not applied and once when regularization was applied. The values were same in both the cases. Hence it can be concluded that for this model regularization does not help.\n",
        "\n",
        "8)Which independent variables are significant?\n",
        "Ans: Variables are significant when p-value is less than 0.05.'Administrative', 'Administrative_Duration', 'Informational', 'Informational_Duration', 'Browser', 'TrafficType', and 'Weekend' all other variables have p-value less than 0.05. So, it can be said that all variables are significant.\n",
        "\n",
        "9) Which hyperparameters are important?\n",
        "Ans: To find best set a hyperparameter and combinations of interacting hyperparameters for a given dataset hyperparameters tuning is used. It objectively searches different values for model hyperparameters and chooses a subset that results in a model that achieves the best performance on a given dataset. For this model tuning is performed using RandomForestRegressor. The best hyperparameters for this model are: {'n_estimators': 100, 'min_samples_split': 2, 'max_depth': 500}"
      ],
      "metadata": {
        "id": "4rawFkNGmbXz"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pI5RNbTdmik6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "LICENSE:"
      ],
      "metadata": {
        "id": "l9PmV4qUyaPD"
      }
    }
  ]
}